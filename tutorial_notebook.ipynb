{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "916c0d13-a5fe-4581-8a65-2f426011b9e1",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f40cd2f-876b-4764-a0ea-0d56783ae4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fnmatch\n",
    "import logging\n",
    "import math\n",
    "import multiprocessing\n",
    "import os\n",
    "import tempfile\n",
    "from typing import Any, Dict, List, Optional, Tuple\n",
    "\n",
    "import joblib\n",
    "import pytorch_lightning as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import requests\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "logger = logging.getLogger(\"notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c3daa1-fe6f-4554-8401-3f37ae3d63ff",
   "metadata": {},
   "source": [
    "## GPT Papers\n",
    "Here are the papers for reference\n",
    "* GPT-1: [Improving Language Understanding\n",
    "by Generative Pre-Training](https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf)\n",
    "* GPT-2: [Language Models are Unsupervised Multitask Learners](https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)\n",
    "* GPT-3: [Language Models are Few-Shot Learners](https://arxiv.org/pdf/2005.14165.pdf)\n",
    "\n",
    "\n",
    "## Implementing the GPT-2 decoder stack\n",
    "Here is the decoder-only stack from the GPT-1 paper:\n",
    "\n",
    "![](https://i.stack.imgur.com/Kb8Gq.png)\n",
    "\n",
    "NOTE a few changes introduced in GPT-2: \n",
    "* An additional layer normalization was added after the final self-attention block.\n",
    "* We always have the feedforward layer four times the size of the bottleneck layer, dff = 4 âˆ— dmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab5e965e-74c2-464c-95ea-053604c80c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from char import GptTransfomer\n",
    "\n",
    "\n",
    "class TutorialGptTransfomer(GptTransfomer):\n",
    "    \"\"\"\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size: int,\n",
    "        weight_decay: float = 0.1,\n",
    "        betas: Tuple[float, float] = (0.9, 0.95),\n",
    "        learning_rate: float = 3e-4,\n",
    "        n_embedding_dims: int = 768,\n",
    "        block_size: int = 128,\n",
    "        embedding_drop_probability: float = 0.1,\n",
    "        n_layers: int = 12,\n",
    "        n_attention_heads: int = 4,\n",
    "        residual_drop_probability: float = 0.1,\n",
    "        self_attention_drop_probability: float = 0.1,\n",
    "    ):\n",
    "        super().__init__(vocab_size=vocab_size)\n",
    "        self.hparams: Any  # Adding this line to please mypy.\n",
    "        # Saves all of the arguments passed to __init__ to self.hparams\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        # ==============\n",
    "        # IMPLEMENT THIS\n",
    "        # ==============\n",
    "        \n",
    "        # Initialise parameters.\n",
    "        self.apply(self._init_weights)\n",
    "        n_parameters: int = sum(p.numel() for p in self.parameters())\n",
    "        logger.info(f\"Number of parameters: {n_parameters}\")\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"forward pass of the model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.Tensor\n",
    "            input tensor of shape (batch_size, block_size). Here `x` is a\n",
    "            sequence of tokens, where each token is an integer in the range\n",
    "            [0, vocab_size).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        logits : torch.Tensor\n",
    "            output tensor of shape (batch_size, block_size, vocab_size).\n",
    "        \"\"\"\n",
    "        batch_size, block_size = x.shape\n",
    "        \n",
    "        # ==============\n",
    "        # IMPLEMENT THIS\n",
    "        # ==============\n",
    "        \n",
    "        return logits\n",
    "    \n",
    "    \n",
    "# TutorialGptTransfomer(vocab_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3bad2d-80d4-4a00-a82c-43fce0d9c115",
   "metadata": {},
   "source": [
    "## GPT Transformer Block (we need to stack 12 of these)\n",
    "\n",
    "Official implementation of the block:\n",
    "* Official GPT-2 MLP implementation [here](https://github.com/openai/gpt-2/blob/a74da5d99abaaba920de8131d64da2862a8f213b/src/model.py#L115-L120), and MLP is invoked [here](https://github.com/openai/gpt-2/blob/a74da5d99abaaba920de8131d64da2862a8f213b/src/model.py#L128).\n",
    "* Official GPT-2 block implementation [here](https://github.com/openai/gpt-2/blob/a74da5d99abaaba920de8131d64da2862a8f213b/src/model.py#L123-L130).\n",
    "\n",
    "<img src=\"https://iili.io/poaGee.png\" alt=\"drawing\" width=\"200\"/>\n",
    "\n",
    "_Also note GPT-2 introduced over GPT-1:_\n",
    "* LayerNorm was moved to the input of each sub-block, similar to a pre-activation residual network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a78f57d-b58e-4050-affd-75fee552ed7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GptTransformerBlock(torch.nn.Module):\n",
    "    \"\"\"an unassuming Transformer block\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_embedding_dims: int,\n",
    "        n_attention_heads: int,\n",
    "        self_attention_drop_probability: float,\n",
    "        residual_drop_probability: float,\n",
    "        block_size: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        # ==============\n",
    "        # IMPLEMENT THIS\n",
    "        # ==============\n",
    "\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward pass the transformer block.\"\"\"\n",
    "        \n",
    "        # ==============\n",
    "        # IMPLEMENT THIS\n",
    "        # ==============\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9630d3f-05b0-427f-ba5f-e0383b8a756c",
   "metadata": {},
   "source": [
    "## Implementing the causal self-attention\n",
    "\n",
    "Note there is the causal mask:\n",
    "![](https://raw.githubusercontent.com/raviteja-ganta/raviteja-ganta.github.io/main/assets/images/Transformers/tf_24.png)\n",
    "\n",
    "The rows here allow us to attend with each word in the sentance. We want to mask to prevent words from being attended with future words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef22d30a-b5b7-41be-9772-65236c1915e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "block_size: int = 10\n",
    "# Build the causal mask.\n",
    "triangle_matrix: torch.Tensor = torch.tril(torch.ones(block_size, block_size))\n",
    "is_future_token_mask: torch.Tensor = torch.isclose(triangle_matrix, torch.tensor(0.0))\n",
    "# Plot the thing:\n",
    "plt.imshow(is_future_token_mask)\n",
    "_ = plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0a64f7-91f1-4195-a5ba-c024cb458ce7",
   "metadata": {},
   "source": [
    "Lets keep the mask in the back of our minds. \n",
    "\n",
    "Next lets implement the self-attention module. All the steps looks something like:\n",
    "![](https://raw.githubusercontent.com/raviteja-ganta/raviteja-ganta.github.io/main/assets/images/Transformers/tf_19.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f4d875-7b20-457d-97d7-e0927b6a544a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalSelfAttention(torch.nn.Module):\n",
    "    \"\"\"A Causal Self-Attention module.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_embedding_dims: int,\n",
    "        n_attention_heads: int,\n",
    "        self_attention_drop_probability: float,\n",
    "        residual_drop_probability: float,\n",
    "        block_size: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        assert n_embedding_dims % n_attention_heads == 0, (\n",
    "            \"Number of embedding dimensions should be divisible by the number \"\n",
    "            \"of attention heads, this means each head gets an equal share of \"\n",
    "            \"the embedding dimensions.\"\n",
    "        )\n",
    "        \n",
    "        # ==============\n",
    "        # IMPLEMENT THIS\n",
    "        # ==============\n",
    "\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Compute the self-attention.\"\"\"\n",
    "        batch_size, block_size, n_embedding_dims = x.shape\n",
    "        \n",
    "        # ==============\n",
    "        # IMPLEMENT THIS\n",
    "        # ==============\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gpt)",
   "language": "python",
   "name": "gpt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
